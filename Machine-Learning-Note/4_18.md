# Decision Tree
## 剪枝
剪枝是决策树应对过拟合的方法
过拟合的表现：决策树深度过大，特别到了底层数量少时，由于噪声扰动产生的不同会被划分开
### 两种策略：预剪枝和后剪枝 
留出法划分出验证集判断
后剪枝从深度大处往上验证
预剪枝显著增加前拟合风险：只看一层的风险
一般情况下泛化性能后剪枝更好，但有时候预剪枝更适合，比如不断更新的大数据，不太可能构建出完全树
连续属性的处理：n个样本，(n-1)个二阶划分，再利用信息熵判断
## 缺失值
样本赋权 权重划分
从根节点到叶节点的路径对应一条规则
C4.5Rule会将规则泛化，泛化能力强于决策树
## 单变量决策树
产生轴平行分类面
对于非线性问题，决策树是进行分段线性处理
多变量决策树：倾斜决策树，最优划分属性变为线性分类器
混合决策树：结点上嵌入神经网络或其他非线性模型
